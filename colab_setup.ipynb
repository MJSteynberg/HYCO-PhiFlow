{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224298ee",
   "metadata": {},
   "source": [
    "# HYCO-PhiFlow on Google Colab\n",
    "\n",
    "This notebook sets up and runs your HYCO-PhiFlow experiments on Google Colab with GPU acceleration.\n",
    "\n",
    "**Important:** Make sure you've uploaded your HYCO-PhiFlow folder to Google Drive first!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44d57a",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b032511",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q hydra-core omegaconf phiflow==2.5.3 torch torchvision matplotlib tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b6ecf9",
   "metadata": {},
   "source": [
    "## 3. Setup Project Paths\n",
    "\n",
    "**Update the `GDRIVE_PROJECT_PATH` below to match where you uploaded your project in Google Drive!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc10b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# UPDATE THIS PATH to your Google Drive location\n",
    "GDRIVE_PROJECT_PATH = \"/content/drive/MyDrive/HYCO-PhiFlow\"\n",
    "\n",
    "# Local fast storage paths\n",
    "LOCAL_PROJECT = \"/content/HYCO-PhiFlow\"\n",
    "LOCAL_CACHE = \"/content/cache\"\n",
    "LOCAL_DATA = \"/content/data\"\n",
    "\n",
    "# Create local directories\n",
    "os.makedirs(LOCAL_CACHE, exist_ok=True)\n",
    "os.makedirs(LOCAL_DATA, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Google Drive project: {GDRIVE_PROJECT_PATH}\")\n",
    "print(f\"✓ Local project: {LOCAL_PROJECT}\")\n",
    "print(f\"✓ Local cache: {LOCAL_CACHE}\")\n",
    "print(f\"✓ Local data: {LOCAL_DATA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0921902",
   "metadata": {},
   "source": [
    "## 4. Copy Code to Local Storage\n",
    "\n",
    "Copy the source code and configs to local storage for faster access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy essential project files to local storage (faster than Drive)\n",
    "if os.path.exists(LOCAL_PROJECT):\n",
    "    shutil.rmtree(LOCAL_PROJECT)\n",
    "\n",
    "# Copy source code, configs, and run script\n",
    "shutil.copytree(GDRIVE_PROJECT_PATH, LOCAL_PROJECT, \n",
    "                ignore=shutil.ignore_patterns('data', 'cache', 'outputs', 'results', \n",
    "                                               '__pycache__', '*.pyc', '.git'))\n",
    "\n",
    "print(\"✓ Code copied to local storage\")\n",
    "\n",
    "# Change to project directory\n",
    "%cd {LOCAL_PROJECT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6f1af9",
   "metadata": {},
   "source": [
    "## 5. Copy or Generate Data\n",
    "\n",
    "Choose ONE option:\n",
    "- **Option A:** Copy existing data from Google Drive (if you already have generated data)\n",
    "- **Option B:** Generate data fresh on Colab (recommended for first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288312cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Copy existing data from Google Drive (uncomment if needed)\n",
    "# DATASET_NAME = \"smoke_256\"  # Change to your dataset\n",
    "# source_data = f\"{GDRIVE_PROJECT_PATH}/data/{DATASET_NAME}\"\n",
    "# if os.path.exists(source_data):\n",
    "#     shutil.copytree(source_data, f\"{LOCAL_DATA}/{DATASET_NAME}\")\n",
    "#     print(f\"✓ Copied {DATASET_NAME} data to local storage\")\n",
    "\n",
    "# Option B: Generate data on Colab (recommended)\n",
    "print(\"Data will be generated when you run the experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88308a",
   "metadata": {},
   "source": [
    "## 6. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2cf77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected! Go to Runtime → Change runtime type → Select GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f13713",
   "metadata": {},
   "source": [
    "## 7. Generate Data (if needed)\n",
    "\n",
    "Generate simulation data and cache it to local storage for fast training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for your experiment\n",
    "# This will store raw data in LOCAL_DATA and cache in LOCAL_CACHE\n",
    "\n",
    "!python run.py --config-name=smoke_experiment \\\n",
    "    run_params.mode=[generate] \\\n",
    "    data.data_dir={LOCAL_DATA}/smoke_256 \\\n",
    "    data.cache_dir={LOCAL_CACHE}/smoke_256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f12b03",
   "metadata": {},
   "source": [
    "## 8. Run Training\n",
    "\n",
    "Train your model using the local cache for maximum speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with local cache (fast!)\n",
    "!python run.py --config-name=smoke_experiment \\\n",
    "    run_params.mode=[train] \\\n",
    "    data.data_dir={LOCAL_DATA}/smoke_256 \\\n",
    "    data.cache_dir={LOCAL_CACHE}/smoke_256 \\\n",
    "    trainer_params.epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32900bb4",
   "metadata": {},
   "source": [
    "## 9. Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc398c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "!python run.py --config-name=smoke_experiment \\\n",
    "    run_params.mode=[evaluate] \\\n",
    "    data.data_dir={LOCAL_DATA}/smoke_256 \\\n",
    "    data.cache_dir={LOCAL_CACHE}/smoke_256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f033db3c",
   "metadata": {},
   "source": [
    "## 10. Save Results Back to Google Drive\n",
    "\n",
    "Save trained models and results to Google Drive so they persist after the session ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ec8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped backup folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "backup_dir = f\"{GDRIVE_PROJECT_PATH}/colab_results_{timestamp}\"\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "# Copy results\n",
    "if os.path.exists(\"results\"):\n",
    "    shutil.copytree(\"results\", f\"{backup_dir}/results\")\n",
    "    print(\"✓ Saved results to Drive\")\n",
    "\n",
    "# Copy outputs (logs)\n",
    "if os.path.exists(\"outputs\"):\n",
    "    shutil.copytree(\"outputs\", f\"{backup_dir}/outputs\")\n",
    "    print(\"✓ Saved outputs to Drive\")\n",
    "\n",
    "# Optionally save cache (if you want to reuse it later)\n",
    "# Warning: This can be large!\n",
    "# shutil.copytree(LOCAL_CACHE, f\"{backup_dir}/cache\")\n",
    "\n",
    "print(f\"\\n✓ All results saved to: {backup_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477b25f",
   "metadata": {},
   "source": [
    "## 11. Quick Test Run (Optional)\n",
    "\n",
    "Run a quick test to make sure everything works before starting a long training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85239b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with fewer epochs\n",
    "!python run.py --config-name=smoke_quick_test \\\n",
    "    data.data_dir={LOCAL_DATA}/smoke_128 \\\n",
    "    data.cache_dir={LOCAL_CACHE}/smoke_128 \\\n",
    "    trainer_params.epochs=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ae657",
   "metadata": {},
   "source": [
    "## 12. Monitor Training (Optional)\n",
    "\n",
    "View training metrics and loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have tensorboard logs, you can view them\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec572c1f",
   "metadata": {},
   "source": [
    "## Tips for Using Colab\n",
    "\n",
    "1. **Session Management:**\n",
    "   - Sessions timeout after ~12 hours of inactivity\n",
    "   - Save checkpoints frequently\n",
    "   - Use the save cell (#10) regularly during long training\n",
    "\n",
    "2. **Speed Optimization:**\n",
    "   - Always use local storage (`/content/`) for data and cache\n",
    "   - Only save results back to Drive, not intermediate data\n",
    "   - Keep raw data and cache in `/content/` during training\n",
    "\n",
    "3. **Resource Limits:**\n",
    "   - Free tier: ~12-15GB GPU RAM, ~12GB system RAM\n",
    "   - Adjust batch size if you get OOM errors\n",
    "   - Monitor GPU usage: `!nvidia-smi`\n",
    "\n",
    "4. **Resuming Work:**\n",
    "   - If session disconnects, re-run setup cells (1-6)\n",
    "   - Your saved models are safe in Google Drive\n",
    "   - You may need to regenerate cache if not saved\n",
    "\n",
    "5. **Alternative Experiments:**\n",
    "   - Change `--config-name=` to run different experiments\n",
    "   - Options: `burgers_experiment`, `heat_physical_experiment`, etc.\n",
    "   - Modify parameters with Hydra overrides as shown above"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
