# @package _global_

# Hybrid Training: Neither Model Sees Real Data
# Use case: Extreme experimental setup where models learn only from each other
#           (Real data is used only for initial warmup/validation)

defaults:
  - /trainer: hybrid
  - /data: burgers_128
  - /model/synthetic: unet
  - /model/physical: burgers
  - /logging: default

trainer_params:
  train_sim: [0, 1, 2]
  val_sim: [3]
  
  epochs: 50
  batch_size: 16
  num_predict_steps: 10
  
  # Augmentation configuration
  augmentation:
    alpha: 1.0  # Equal synthetic and generated data
  
  # Hybrid configuration with no real data access
  hybrid:
    num_cycles: 20  # More cycles for convergence
    synthetic_epochs_per_cycle: 5
    physical_epochs_per_cycle: 5
    warmup_synthetic_epochs: 20  # CRITICAL: Need substantial warmup on real data
    
    # KEY PARAMETER: Neither model sees real data after warmup
    real_data_access: 'neither'
  
  # Synthetic model settings
  synthetic:
    learning_rate: 5e-5  # Lower LR for stability
    weight_decay: 1e-4   # Stronger regularization
    optimizer: adam
    scheduler: cosine
  
  # Physical model settings
  physical:
    method: 'L-BFGS-B'
    abs_tol: 1e-6

run_params:
  model_type: "hybrid"
  task: "train"

# Expected behavior:
# - Warmup (20 epochs):
#   - Synthetic trains on REAL data (establishes baseline)
# - Cycle 1-20:
#   1. Physical trains on SYNTHETIC predictions only
#   2. Synthetic trains on PHYSICS predictions only
#   - Models iteratively refine each other without touching real data
#
# Use this when:
#   - Testing theoretical limits of self-supervised learning
#   - Investigating if models can co-evolve without ground truth
#   - Exploring adversarial-like training dynamics
#
# WARNING: This is highly experimental!
#   - Requires good warmup to establish reasonable synthetic baseline
#   - May diverge if models reinforce each other's errors
#   - Not recommended for production use
#   - Primarily for research/investigation of model interactions
