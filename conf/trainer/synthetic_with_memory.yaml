# @package _global_.trainer_params
# Quick test - memory monitoring controlled via logging config
# Note: Hardcoded behaviors same as synthetic.yaml

learning_rate: 0.0001
batch_size: 16
epochs: 2
num_predict_steps: 4

train_sim: []
val_sim: null

# Validation settings
validate_every: 1
validation_rollout_steps: 10  # Short rollout for quick testing

# Optimizer settings
optimizer: 'adam'
scheduler: 'cosine'
weight_decay: 0.0

# Checkpoint settings
checkpoint_freq: 1
